var documenterSearchIndex = {"docs":
[{"location":"functions/","page":"Functions","title":"Functions","text":"Modules = [GroupIWord2Vec]","category":"page"},{"location":"functions/#GroupIWord2Vec.GroupIWord2Vec","page":"Functions","title":"GroupIWord2Vec.GroupIWord2Vec","text":"GroupIWord2Vec\n\nThis is the main module file that organizes all the word embedding functionality.\n\nTypes\n\nWordEmbedding: Main data structure for word embeddings\n\nFunctions\n\ntrain_model: Train new word embeddings\nload_embeddings: Load pre-trained embeddings\nget_vector: Get a word's vector\nget_similarity: Find top n similar words\ncosine_similarity: Compute similarity of two words\n\n\n\n\n\n","category":"module"},{"location":"functions/#GroupIWord2Vec.cosine_similarity-Tuple{WordEmbedding, Any, Any}","page":"Functions","title":"GroupIWord2Vec.cosine_similarity","text":"cosine_similarity(wv, string_1, string_2)\n\nPurpose: Return the cosine similarity value between two words\n\n\n\n\n\n","category":"method"},{"location":"functions/#GroupIWord2Vec.get_top_similarity_of_vector","page":"Functions","title":"GroupIWord2Vec.get_top_similarity_of_vector","text":"get_top_similarity_of_vector(wv, vector, int)\n\nPurpose: Find the n (default n = 10) most similar words to a given vector and return the matching strings\n\n\n\n\n\n","category":"function"},{"location":"functions/#GroupIWord2Vec.get_top_similarity_of_word","page":"Functions","title":"GroupIWord2Vec.get_top_similarity_of_word","text":"get_top_similarity_of_word(wv, string, int)\n\nPurpose: Find the n (default n = 10) most similar words to a given word and return the matching strings\n\n\n\n\n\n","category":"function"},{"location":"functions/#GroupIWord2Vec.get_vector_from_word-Tuple{WordEmbedding, Any}","page":"Functions","title":"GroupIWord2Vec.get_vector_from_word","text":"get_vector_from_word(wv, string)\n\nPurpose: Get the vector representation of an input word from the WordEmbedding\n\n\n\n\n\n","category":"method"},{"location":"functions/#GroupIWord2Vec.get_word_embedding-Tuple{String}","page":"Functions","title":"GroupIWord2Vec.get_word_embedding","text":"placeholder for real function. only works for berlin, germany, rome, italy, madrid, spain, paris, france returns 300d embedding for a string\n\n\n\n\n\n","category":"method"},{"location":"functions/#GroupIWord2Vec.read_binary_format-Union{Tuple{T}, Tuple{AbstractString, Type{T}, Bool, Char, Int64}} where T<:Real","page":"Functions","title":"GroupIWord2Vec.read_binary_format","text":"This function reads word embeddings (word->vector mappings) from a binary file\n\nIt requires the following Parameters:\n\nfilepath: where the file is located\n\nT: what kind of numbers we want (like decimal numbers)\n\nnormalize: whether to make all vectors have length 1\n\n–-> This can be useful for comparison since the length of the vector does not\n\nmatter, only its direction\n\nseparator: what character separates the values in the file (like space or comma)\n\nskip_bytes: how many bytes to skip after each word-vector pair (usually for handling separators)\n\nInstead of reading lines of text and parsing numbers it reads words until it hits a separator\n\nReads raw bytes and converts them directly to numbers\n\n\n\n\n\n","category":"method"},{"location":"functions/#GroupIWord2Vec.read_text_format-Union{Tuple{T}, Tuple{AbstractString, Type{T}, Bool, Char}} where T<:Real","page":"Functions","title":"GroupIWord2Vec.read_text_format","text":"This function reads word embeddings (word->vector mappings) from a text file\n\nIt requires the following Parameters:\n\nfilepath: where the file is located\n\nT: what kind of numbers we want (like decimal numbers)\n\nnormalize: whether to make all vectors have length 1\n\n–-> This can be useful for comparison since the length of the vector does not\n\nmatter, only its direction\n\nseparator: what character separates the values in the file (like space or comma)\n\n\n\n\n\n","category":"method"},{"location":"functions/#GroupIWord2Vec.reduce_to_2d","page":"Functions","title":"GroupIWord2Vec.reduce_to_2d","text":"This function reduces the dimension of a matrix from NxM to Nx\"numberofpc\" with a PCA.  It returns the projected data.\n\n\n\n\n\n","category":"function"},{"location":"functions/#GroupIWord2Vec.show_relations-Tuple{Vararg{String}}","page":"Functions","title":"GroupIWord2Vec.show_relations","text":"This Function creates a plot of the relations of the arguments like this: arg1==>arg2, arg3==>arg4, ... Note: Use an even number of inputs!\n\n\n\n\n\n","category":"method"},{"location":"functions/#GroupIWord2Vec.train_model-Tuple{AbstractString, AbstractString}","page":"Functions","title":"GroupIWord2Vec.train_model","text":" word2vec(train, output; size=100, window=5, sample=1e-3, hs=0,  negative=5, threads=12, iter=5, min_count=5, alpha=0.025, debug=2, binary=1, cbow=1, save_vocal=Nothing(), read_vocab=Nothing(), verbose=false,)\n\nParameters for training:\n    train <file>\n        Use text data from <file> to train the model\n    output <file>\n        Use <file> to save the resulting word vectors / word clusters\n    size <Int>\n        Set size of word vectors; default is 100\n    window <Int>\n        Set max skip length between words; default is 5\n    sample <AbstractFloat>\n        Set threshold for occurrence of words. Those that appear with\n        higher frequency in the training data will be randomly\n        down-sampled; default is 1e-5.\n    hs <Int>\n        Use Hierarchical Softmax; default is 1 (0 = not used)\n    negative <Int>\n        Number of negative examples; default is 0, common values are \n        5 - 10 (0 = not used)\n    threads <Int>\n        Use <Int> threads (default 12)\n    iter <Int>\n        Run more training iterations (default 5)\n    min_count <Int>\n        This will discard words that appear less than <Int> times; default\n        is 5\n    alpha <AbstractFloat>\n        Set the starting learning rate; default is 0.025\n    debug <Int>\n        Set the debug mode (default = 2 = more info during training)\n    binary <Int>\n        Save the resulting vectors in binary moded; default is 0 (off)\n    cbow <Int>\n        Use the continuous back of words model; default is 1 (skip-gram\n        model)\n    save_vocab <file>\n        The vocabulary will be saved to <file>\n    read_vocab <file>\n        The vocabulary will be read from <file>, not constructed from the\n        training data\n    verbose <Bool>\n        Print output from training\n\n\n\n\n\n","category":"method"},{"location":"functions/#GroupIWord2Vec.word_analogy","page":"Functions","title":"GroupIWord2Vec.word_analogy","text":"word_analogy(wv::WordEmbedding, pos_words::Vector{String}, neg_words::Vector{String}, n::Int=5)\n\nPerforms word analogy calculations like: king - man + woman = queen Returns the n most similar words to the resulting vector.\n\nArguments\n\nwv: WordEmbedding containing the vocabulary and vectors\npos_words: Words to add to the calculation\nneg_words: Words to subtract from the calculation\nn: Number of similar words to return (default: 5)\n\nReturns\n\nVector{String}: n most similar words to the resulting vector\n\nExample\n\n# Find: king - man + woman = ?\nresult = word_analogy(wv, [\"king\", \"woman\"], [\"man\"])\n# Should return [\"queen\", ...]\n\n\n\n\n\n","category":"function"},{"location":"getting_started/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"getting_started/#1)-Download","page":"Getting Started","title":"1) Download","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We can't use Pluto's environments but have to create our own","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"julia> using Pkg\njulia> Pkg.activate(\"MyEnv\")\njulia> Pkg.add(url=\"https://github.com/graupnej/GroupIWord2Vec.jl\")\njulia> using GroupIWord2Vec","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Below is an overview of the project's main components","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"GroupIWord2Vec.jl               \n├── src/                        # Contains core modules for the package\n│   ├── GroupIWord2Vec.jl       # Main entry point for the project\n│   ├── functions.jl            # Word/vector functions\n│   └── model.jl                # Model functions\n├── test/                       # Unit tests to validate functionalities\n│   ├── runtests.jl             # Combination of every testing routine\n│   ├── test_functions.jl       # Testing routine for word/vector functions \n│   └── test_model.jl           # Testing routine for model functions\n├── docs/                       # Documentation for the package\n├── Manifest.toml               # Detailed dependency lock file that tracks exact versions of project dependencies\n├── Project.toml                # Project configuration file defining package dependencies\n└── README.md                   # Main documentation file containing getting started","category":"page"},{"location":"getting_started/#2)-Running-a-simple-example","page":"Getting Started","title":"2) Running a simple example","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Download https://mattmahoney.net/dc/text8.zip and store it in the current working directory. To train the model with text8 use train_model()","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"julia> train_model(\"text8\", \"text8.txt\", verbose = true)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"The resulting word vectors are saved in a text format file (here) named text8txt. Import the obtained word vectors from text8txt into Julia using load_embeddings()","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"julia> model = load_embeddings(\"./text8.txt\")","category":"page"},{"location":"getting_started/#Some-functionalities","page":"Getting Started","title":"Some functionalities","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"get_vector_from_word(): Get the vector representation of a word","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"julia> get_vector_from_word(model, \"king\")","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"cosine_similarity(): Returns cosine of the angle between two vectors in a word embedding space","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"julia> cosine_similarity(model, \"king\", \"prince\")","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"It ranges from -1 to 1, where 1 indicates high similarity, 0 indicates no similarity and -1 indicates opposite directions.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"get_top_similarity_of_word(): Find the n most similar words to a given word and return the matching strings","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"julia> get_top_similarity_of_word(model, \"king\", 5)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"word_analogy(): Performs word analogy calculations (e.g. king - man + woman = queen)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"julia> word_analogy(model, [\"king\", \"woman\"], [\"man\"])","category":"page"},{"location":"getting_started/#3)-Running-a-large-example","page":"Getting Started","title":"3) Running a large example","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"As an alternative (larger) example use a text corpus from e.g. FastText (.bin & .vec file) https://fasttext.cc/docs/en/pretrained-vectors.html with about 33 million words. Store this file in the current working directory and apply the same functions as in the previous example.","category":"page"},{"location":"getting_started/#For-Developers","page":"Getting Started","title":"For Developers","text":"","category":"section"},{"location":"getting_started/#1)-Download-the-code","page":"Getting Started","title":"1) Download the code","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"git clone https://github.com/graupnej/GroupIWord2Vec.jl.git","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Navigate to the cloned directory and launch julia. Activate the project environment to tell Julia to use the Project.toml","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"julia> using Pkg\njulia> Pkg.activate(\".\")","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Resolve dependencies and create a Manifest.toml file","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"julia> Pkg.instantiate()","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Precompile the project to ensure all dependencies and the code is ready","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"julia> Pkg.precompile()","category":"page"},{"location":"getting_started/#2)-Run-tests","page":"Getting Started","title":"2) Run tests","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"To verify everything is working correctly run the code coverage tests","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"julia> Pkg.test(\"GroupIWord2Vec\")","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"This covers all the tests. To execute a specific test (e.g. Functions)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"julia> Pkg.test(\"GroupIWord2Vec\", test_args=[\"Functions\"])","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = GroupIWord2Vec","category":"page"},{"location":"#Explanation","page":"Home","title":"Explanation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"}]
}
